### 前端大文件上传的解决方案

前端处理大文件上传时，需要解决**网络中断**、**内存溢出**、**服务器限制**等核心问题。以下是目前主流的解决方案及其技术实现：

### 一、分块上传（Chunk Upload）

#### 核心原理

将大文件切割为多个小块（通常5-10MB/块），分别上传，服务器端再合并这些块。

#### 关键技术

- **文件切片**：使用 `File.slice()` 方法切割文件
- **并发控制**：限制同时上传的块数量，避免浏览器崩溃
- **断点续传**：记录已上传的块，失败时只重传未上传的块

#### 实现示例

```javascript
// 分块上传示例
async function uploadFile(file) {
  const chunkSize = 5 * 1024 * 1024; // 5MB 每块
  const totalChunks = Math.ceil(file.size / chunkSize);

  // 并行上传多个块（限制并发数为3）
  const uploadPromises = [];
  for (let i = 0; i < totalChunks; i++) {
    const chunk = file.slice(i * chunkSize, (i + 1) * chunkSize);
    uploadPromises.push(uploadChunk(chunk, i, totalChunks));

    // 控制并发数
    if (uploadPromises.length >= 3) {
      await Promise.race(uploadPromises);
    }
  }

  await Promise.all(uploadPromises);
  await mergeChunks(file.name, totalChunks); // 通知服务器合并文件
}
```

### 二、断点续传（Resumable Upload）

#### 核心原理

记录已上传的文件块信息，当上传中断时，只需重新上传未完成的部分。

#### 关键技术

- **文件唯一标识**：使用 `SparkMD5` 计算文件哈希值作为 ID
- **进度记录**：通过 `localStorage` 或后端存储记录已上传的块
- **秒传验证**：先上传文件哈希，服务器验证是否已有相同文件

#### 实现示例

```javascript
// 断点续传示例
async function uploadWithResume(file) {
  // 计算文件哈希（异步计算，避免阻塞UI）
  const fileHash = await calculateFileHash(file);

  // 检查服务器已上传的块
  const existingChunks = await checkExistingChunks(fileHash);

  // 只上传未完成的块
  const chunkSize = 5 * 1024 * 1024;
  const totalChunks = Math.ceil(file.size / chunkSize);

  for (let i = 0; i < totalChunks; i++) {
    if (!existingChunks.includes(i)) {
      const chunk = file.slice(i * chunkSize, (i + 1) * chunkSize);
      await uploadChunk(chunk, i, totalChunks, fileHash);
    }
  }

  await mergeChunks(fileHash, totalChunks);
}
```

### 三、并发上传（Concurrent Upload）

#### 核心原理

同时上传多个文件块，利用多线程提升上传速度。

#### 关键技术

- **Web Worker**：在后台线程计算文件哈希，避免阻塞主线程
- **Fetch API**：支持并发请求，替代传统的 XHR
- **请求优先级**：高优先级请求（如文件块）优先处理

#### 实现示例

```javascript
// 并发上传示例
async function uploadConcurrently(file) {
  const chunkSize = 5 * 1024 * 1024;
  const totalChunks = Math.ceil(file.size / chunkSize);

  // 使用 Web Worker 计算哈希
  const worker = new Worker('hash-worker.js');
  worker.postMessage(file);
  worker.onmessage = (e) => {
    const fileHash = e.data;
    // 哈希计算完成后开始上传
    uploadChunksConcurrently(file, fileHash, totalChunks);
  };
}

// 并发上传所有块（限制并发数）
async function uploadChunksConcurrently(file, fileHash, totalChunks) {
  const concurrency = 5; // 最大并发数
  let activeUploads = 0;
  let completed = 0;

  for (let i = 0; i < totalChunks; i++) {
    // 控制并发数
    while (activeUploads >= concurrency) {
      await new Promise((resolve) => setTimeout(resolve, 100));
    }

    activeUploads++;
    const chunk = file.slice(i * chunkSize, (i + 1) * chunkSize);

    uploadChunk(chunk, i, totalChunks, fileHash)
      .then(() => {
        activeUploads--;
        completed++;
        updateProgress(completed / totalChunks);
      })
      .catch((error) => {
        activeUploads--;
        console.error('Chunk upload failed:', error);
        // 处理失败逻辑（重试等）
      });
  }
}
```

### 四、秒传功能（Instant Upload）

#### 核心原理

通过计算文件哈希值，与服务器已存储的文件比对，若存在则直接完成上传。

#### 关键技术

- **哈希算法**：常用 `MD5` 或 `SHA-1` 计算文件指纹
- **增量哈希**：对于超大文件，只计算文件前部分和后部分的哈希
- **元数据存储**：服务器维护文件哈希与存储路径的映射表

#### 实现示例

```javascript
// 秒传功能示例
async function uploadWithInstantCheck(file) {
  // 快速计算文件哈希（取前中后各1MB）
  const fileHash = await calculatePartialHash(file);

  // 检查服务器是否已有该文件
  const exists = await checkFileExists(fileHash);

  if (exists) {
    // 文件已存在，直接完成上传
    showSuccess('文件已存在，秒传成功！');
    return;
  }

  // 文件不存在，正常上传
  uploadFile(file, fileHash);
}
```

### 五、拖拽上传（Drag-and-Drop）

#### 核心原理

利用 HTML5 的 `DragEvent` 和 `DataTransfer` API，实现文件拖拽功能。

#### 关键技术

- **拖拽区域**：监听 `dragover`、`dragleave` 和 `drop` 事件
- **文件预览**：使用 `FileReader` 读取文件元数据或缩略图
- **文件夹上传**：支持拖拽整个文件夹（需浏览器支持）

#### 实现示例

```javascript
// 拖拽上传示例
document.getElementById('drop-area').addEventListener('drop', (e) => {
  e.preventDefault();
  const files = e.dataTransfer.files;

  if (files.length > 0) {
    // 处理上传逻辑
    uploadFiles(Array.from(files));
  }
});

// 阻止默认行为，确保拖拽生效
['dragenter', 'dragover', 'dragleave', 'drop'].forEach((eventName) => {
  document.getElementById('drop-area').addEventListener(eventName, preventDefaults, false);
});

function preventDefaults(e) {
  e.preventDefault();
  e.stopPropagation();
}
```

### 六、进度监控与反馈

#### 核心技术

- **XHR 进度事件**：监听 `progress` 事件获取上传进度
- **实时显示**：通过进度条或百分比展示上传状态
- **错误处理**：区分网络错误、服务器错误并提供重试机制

#### 实现示例

```javascript
// 上传进度监控
function uploadChunk(chunk, chunkIndex, totalChunks) {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    xhr.open('POST', '/upload-chunk', true);

    // 监听进度事件
    xhr.upload.addEventListener('progress', (e) => {
      if (e.lengthComputable) {
        const chunkProgress = e.loaded / e.total;
        const overallProgress = (chunkIndex + chunkProgress) / totalChunks;
        updateProgressBar(overallProgress);
      }
    });

    xhr.onload = () => resolve();
    xhr.onerror = () => reject(new Error('上传失败'));

    const formData = new FormData();
    formData.append('chunk', chunk);
    formData.append('chunkIndex', chunkIndex);
    formData.append('totalChunks', totalChunks);

    xhr.send(formData);
  });
}
```

### 七、服务器端合并策略

#### 关键技术

- **临时存储**：按顺序接收文件块，存储在临时目录
- **合并算法**：按索引顺序合并文件块
- **完整性校验**：合并后计算完整文件哈希，与客户端比对

#### 伪代码示例（Node.js）

```javascript
// 服务器端文件合并示例
app.post('/merge-chunks', async (req, res) => {
  const { fileName, totalChunks, fileHash } = req.body;
  const tempDir = path.join(UPLOAD_DIR, fileHash);

  // 创建写入流
  const writeStream = fs.createWriteStream(path.join(UPLOAD_DIR, fileName));

  // 按顺序合并所有块
  for (let i = 0; i < totalChunks; i++) {
    const chunkPath = path.join(tempDir, `${i}.part`);
    const readStream = fs.createReadStream(chunkPath);

    await new Promise((resolve, reject) => {
      readStream.pipe(writeStream, { end: false });
      readStream.on('end', resolve);
      readStream.on('error', reject);
    });

    // 删除临时块
    fs.unlinkSync(chunkPath);
  }

  // 关闭写入流
  writeStream.end();

  // 验证文件完整性（计算哈希并比对）
  const serverHash = await calculateFileHash(path.join(UPLOAD_DIR, fileName));
  if (serverHash === fileHash) {
    res.send({ success: true });
  } else {
    res.status(500).send({ error: '文件合并后校验失败' });
  }
});
```

### 八、总结与最佳实践

| 方案     | 适用场景               | 关键技术点                       |
| -------- | ---------------------- | -------------------------------- |
| 分块上传 | 大文件上传             | File.slice()、并发控制           |
| 断点续传 | 不稳定网络环境         | 文件哈希、进度记录、localStorage |
| 并发上传 | 高速网络，追求极致速度 | Web Worker、Fetch API、并发限制  |
| 秒传     | 重复文件上传           | 文件哈希比对、服务器元数据管理   |
| 拖拽上传 | 提升用户体验           | DragEvent API、文件夹上传支持    |

**最佳实践建议**：

1. 组合使用分块上传 + 断点续传 + 进度监控，覆盖大多数场景
2. 对超大文件（>1GB）使用 Web Worker 计算哈希，避免阻塞 UI
3. 通过 `localStorage` 记录上传进度，支持跨会话断点续传
4. 服务器端做好安全校验，防止恶意分片攻击
5. 提供清晰的上传反馈，包括预估时间、失败重试等交互

通过合理选择和组合这些技术方案，可以有效解决前端大文件上传的各种挑战。
